{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AlexNet architecture consists of eight layers in total.\n",
    "\n",
    "The first five layers are convolutional layers.\n",
    "The sizes of the convolutional filters are 11×11, 5×5, 3×3, 3×3, and 3×3 for the respective convolutional layers.\n",
    "\n",
    "Some of the convolutional layers are followed by max-pooling layers, which help reduce spatial dimensions while retaining important features.\n",
    "\n",
    "The activation function used in the network is the Rectified Linear Unit (ReLU), known for its superior performance compared to sigmoid and tanh functions.\n",
    "\n",
    "After the convolutional layers, there are three fully connected layers.\n",
    "The network’s parameters can be tuned based on the training performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "def get_train_valid_loader(data_dir,\n",
    "                           batch_size,\n",
    "                           augment,\n",
    "                           random_seed,\n",
    "                           valid_size=0.1,\n",
    "                           shuffle=True):\n",
    "    \"\"\"\n",
    "    Utility function to get training and validation data loaders.\n",
    "    \"\"\"\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465],\n",
    "        std=[0.2023, 0.1994, 0.2010],\n",
    "    )\n",
    "\n",
    "    # Define transforms\n",
    "    valid_transform = transforms.Compose([\n",
    "        transforms.Resize((227, 227)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    if augment:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.Resize((227, 227)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "    else:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize((227, 227)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "    # Load the dataset\n",
    "    train_dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=True,\n",
    "        download=True, transform=train_transform,\n",
    "    )\n",
    "\n",
    "    valid_dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=True,\n",
    "        download=True, transform=valid_transform,\n",
    "    )\n",
    "\n",
    "    # Split the dataset into training and validation\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, sampler=train_sampler\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, batch_size=batch_size, sampler=valid_sampler\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "\n",
    "def get_test_loader(data_dir, batch_size, shuffle=True):\n",
    "    \"\"\"\n",
    "    Utility function to get test data loader.\n",
    "    \"\"\"\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    )\n",
    "\n",
    "    # Define transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((227, 227)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=False,\n",
    "        download=True, transform=transform,\n",
    "    )\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle\n",
    "    )\n",
    "\n",
    "    return data_loader\n",
    "\n",
    "\n",
    "# CIFAR10 dataset\n",
    "data_dir = './data'\n",
    "\n",
    "train_loader, valid_loader = get_train_valid_loader(\n",
    "    data_dir=data_dir,\n",
    "    batch_size=64,\n",
    "    augment=False,\n",
    "    random_seed=1,\n",
    ")\n",
    "\n",
    "test_loader = get_test_loader(\n",
    "    data_dir=data_dir,\n",
    "    batch_size=64,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alexnet(nn.Module):\n",
    "    def __init__(self,num_classes = 10): #we use CIFAR10 dataset, hence num_classes = 10 \n",
    "        super(Alexnet,self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3,96, kernel_size=11,stride=4,padding=0),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "                nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(9216, 4096),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.fc2= nn.Sequential(\n",
    "            nn.Linear(4096, num_classes))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        \n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters \n",
    "\n",
    "num_classes = 10 \n",
    "num_epochs = 10 \n",
    "batch_size = 64\n",
    "learning_rate = 0.005\n",
    "\n",
    "model = Alexnet(num_classes).to(device)\n",
    "\n",
    "#loss fn.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate,weight_decay=0.005)\n",
    "\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [704/704], Loss: 0.7973\n",
      "Accuracy of the network on the 5000 validation images: 44.26 %\n",
      "Epoch [2/10], Step [704/704], Loss: 0.5271\n",
      "Accuracy of the network on the 5000 validation images: 43.24 %\n",
      "Epoch [3/10], Step [704/704], Loss: 1.0180\n",
      "Accuracy of the network on the 5000 validation images: 58.62 %\n",
      "Epoch [4/10], Step [704/704], Loss: 1.4266\n",
      "Accuracy of the network on the 5000 validation images: 50.88 %\n",
      "Epoch [5/10], Step [704/704], Loss: 0.7761\n",
      "Accuracy of the network on the 5000 validation images: 61.6 %\n",
      "Epoch [6/10], Step [704/704], Loss: 0.6883\n",
      "Accuracy of the network on the 5000 validation images: 60.34 %\n",
      "Epoch [7/10], Step [704/704], Loss: 1.4347\n",
      "Accuracy of the network on the 5000 validation images: 68.72 %\n",
      "Epoch [8/10], Step [704/704], Loss: 0.5515\n",
      "Accuracy of the network on the 5000 validation images: 68.32 %\n",
      "Epoch [9/10], Step [704/704], Loss: 1.2966\n",
      "Accuracy of the network on the 5000 validation images: 55.46 %\n",
      "Epoch [10/10], Step [704/704], Loss: 0.1995\n",
      "Accuracy of the network on the 5000 validation images: 76.8 %\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                    .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "\n",
    "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
